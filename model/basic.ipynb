{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "from util.read_data import DataReader\n",
    "from util.evaluator import ModelEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'DayOfWeek', 'Month',\n",
       "       'AdjClose', 'OpenDiff', 'CloseDiff', 'AdjCloseDiff', 'HighLowDiff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = DataReader()\n",
    "df = reader.read_all_data_normalized()\n",
    "evaluator = ModelEvaluator(reader.label_scaler)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_features, series_test_volume = reader.get_test_data(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model: $\\hat{E}[v_{d+1}]=v_d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def baseline_model(volume):\n",
    "    pred_volume = volume.shift(1)\n",
    "    return pred_volume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: MSE = 3.684400e+17, R2 = 0.033, confidence interval 95% = (-53,069,427 - 53,341,067)\n"
     ]
    }
   ],
   "source": [
    "baseline_pred_volume = baseline_model(series_test_volume)\n",
    "baseline_model_results = evaluator.evaluate(\"baseline\", series_test_volume[1:], baseline_pred_volume[1:])\n",
    "print(baseline_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline r2 score is **0.033**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another simple model would use moving average over some time window.\n",
    "The model is following: $V_{d+1}=\\frac 1n \\sum_{i=0}^{n-1} V_{d-i}$.\n",
    "We can try multiple n values, le'ts try following values: {1, 3, 5, 10, 50, 100}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_model(volume, n):\n",
    "    pred_volume = volume.rolling(n).mean().shift(1)\n",
    "    return pred_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving_average 1: MSE = 3.684400e+17, R2 = 0.033, confidence interval 95% = (-53,341,067 - 53,069,427)\n",
      "moving_average 3: MSE = 3.099159e+17, R2 = -0.239, confidence interval 95% = (-48,259,465 - 49,530,282)\n",
      "moving_average 5: MSE = 3.128615e+17, R2 = -0.523, confidence interval 95% = (-45,836,522 - 52,614,748)\n",
      "moving_average 10: MSE = 3.298599e+17, R2 = -1.303, confidence interval 95% = (-39,324,762 - 62,279,075)\n",
      "moving_average 50: MSE = 3.892483e+17, R2 = -6.839, confidence interval 95% = (-23,387,014 - 91,775,513)\n",
      "moving_average 100: MSE = 4.390438e+17, R2 = -23.992, confidence interval 95% = (-11,765,661 - 117,942,651)\n"
     ]
    }
   ],
   "source": [
    "window_size = [1,3,5,10,50,100]\n",
    "moving_average_result_list = [evaluator.evaluate(\"moving_average {}\".format(n), \n",
    "                                                 moving_average_model(series_test_volume, n)[n:], series_test_volume[n:]) \n",
    "                                                 for n in window_size]\n",
    "\n",
    "for result in moving_average_result_list:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moving average models for window size <3, 50> does not help much. The window size 1 at least confirms that te algorithm has correct implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le'ts try to use exponential moving average, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_moving_average_model(volume, n):\n",
    "    pred_volume = volume.ewm(span=n).mean().shift(1)\n",
    "    return pred_volume\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving_average 1: MSE = 3.684400e+17, R2 = 0.033, confidence interval 95% = (-53,341,067 - 53,069,427)\n",
      "moving_average 3: MSE = 2.880625e+17, R2 = -0.213, confidence interval 95% = (-46,252,592 - 48,026,359)\n",
      "moving_average 5: MSE = 2.845396e+17, R2 = -0.489, confidence interval 95% = (-42,536,855 - 51,352,553)\n",
      "moving_average 10: MSE = 2.953661e+17, R2 = -1.156, confidence interval 95% = (-38,026,698 - 58,118,071)\n",
      "moving_average 50: MSE = 3.594106e+17, R2 = -6.870, confidence interval 95% = (-25,767,251 - 84,893,406)\n",
      "moving_average 100: MSE = 4.073537e+17, R2 = -18.608, confidence interval 95% = (-20,472,852 - 104,466,639)\n"
     ]
    }
   ],
   "source": [
    "window_size = [1,3,5,10,50,100]\n",
    "exp_moving_average_result_list = [evaluator.evaluate(\"moving_average {}\".format(n),\n",
    "                                                 exp_moving_average_model(series_test_volume, n)[n:], series_test_volume[n:])\n",
    "                                                 for n in window_size]\n",
    "\n",
    "for result in exp_moving_average_result_list:\n",
    "    print(result)\n",
    "data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential moving average on the Volume does not help much either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not try to use first real machine-learning model, random forest classifier. The features will be month of year, day of week, difference between low and high price of previous day and historical parametrized window of following market data: volume data, and changes in the adjusted closing price. Size of the window will be: {3, 5, 10, 50, 100}. The expected result is that the precision will be better with longer time window, but with deminishing returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_model(features, volume):\n",
    "    regressor = RandomForestRegressor(n_estimators=100)\n",
    "    \n",
    "    regressor.fit(features, volume)\n",
    "    return regressor\n",
    "\n",
    "\n",
    "def eval_random_forest_model(n):\n",
    "    # prepare the features\n",
    "    df_enriched = reader.prepare_window_features_for_training(df, n)[n:]\n",
    "\n",
    "    train_features, train_volume = reader.get_train_data(df_enriched)\n",
    "    test_features, test_volume = reader.get_test_data(df_enriched)\n",
    "\n",
    "    regressor = random_forest_model(train_features, train_volume)\n",
    "\n",
    "   \n",
    "    importances = list(zip(train_features.columns, regressor.feature_importances_))\n",
    "    importances.sort(key=lambda x: x[1], reverse = True)\n",
    "    print(\"First 5 Feature importances {}:\".format(n))\n",
    "    for importance in importances[:5]:\n",
    "        print('Feature: {:30} \\t Importance: {}'.format(importance[0], importance[1]))\n",
    "\n",
    "    print(evaluator.evaluate(\"random_forest {} on train: \".format(n), regressor.predict(train_features), train_volume))\n",
    "    random_forest_result = evaluator.evaluate(\"random_forest {} on test:\".format(n), regressor.predict(test_features), test_volume)\n",
    "    print(random_forest_result)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Feature importances 1:\n",
      "Feature: Volume1                        \t Importance: 0.9041325791077832\n",
      "Feature: AdjCloseDiff1                  \t Importance: 0.04137267633802904\n",
      "Feature: DayOfWeek_Monday               \t Importance: 0.009704294101326996\n",
      "Feature: Month_12                       \t Importance: 0.005220430501699296\n",
      "Feature: DayOfWeek_Tuesday              \t Importance: 0.004610987541570389\n",
      "random_forest 1 on train: : MSE = 4.856137e+16, R2 = 0.979, confidence interval 95% = (-7,464,480 - 5,745,820)\n",
      "random_forest 1 on test:: MSE = 2.897712e+17, R2 = 0.060, confidence interval 95% = (-111,726,040 - -17,451,412)\n",
      "\n",
      "First 5 Feature importances 3:\n",
      "Feature: Volume1                        \t Importance: 0.8349494424003479\n",
      "Feature: Volume2                        \t Importance: 0.06276836690472176\n",
      "Feature: Volume3                        \t Importance: 0.03102640283688815\n",
      "Feature: AdjCloseDiff1                  \t Importance: 0.016977103762859033\n",
      "Feature: AdjCloseDiff2                  \t Importance: 0.012984239539341955\n",
      "random_forest 3 on train: : MSE = 4.075474e+16, R2 = 0.982, confidence interval 95% = (-9,753,186 - 2,351,621)\n",
      "random_forest 3 on test:: MSE = 2.479175e+17, R2 = 0.025, confidence interval 95% = (-99,197,782 - -11,996,908)\n",
      "\n",
      "First 5 Feature importances 5:\n",
      "Feature: Volume1                        \t Importance: 0.8268006113954266\n",
      "Feature: Volume2                        \t Importance: 0.05258117732909826\n",
      "Feature: Volume5                        \t Importance: 0.0211175550848147\n",
      "Feature: Volume4                        \t Importance: 0.02073945879711539\n",
      "Feature: Volume3                        \t Importance: 0.015808961216523837\n",
      "random_forest 5 on train: : MSE = 4.102294e+16, R2 = 0.982, confidence interval 95% = (-9,269,428 - 2,877,986)\n",
      "random_forest 5 on test:: MSE = 2.529510e+17, R2 = -0.013, confidence interval 95% = (-95,062,440 - -6,980,802)\n",
      "\n",
      "First 5 Feature importances 10:\n",
      "Feature: Volume1                        \t Importance: 0.822488323051484\n",
      "Feature: Volume2                        \t Importance: 0.0345064284094098\n",
      "Feature: Volume10                       \t Importance: 0.01540688176834316\n",
      "Feature: Volume9                        \t Importance: 0.013301002709835433\n",
      "Feature: Volume4                        \t Importance: 0.012647222674845877\n",
      "random_forest 10 on train: : MSE = 4.097641e+16, R2 = 0.982, confidence interval 95% = (-6,899,451 - 5,248,182)\n",
      "random_forest 10 on test:: MSE = 2.589844e+17, R2 = -0.248, confidence interval 95% = (-93,833,116 - -4,707,207)\n",
      "\n",
      "First 5 Feature importances 50:\n",
      "Feature: Volume1                        \t Importance: 0.811856760843843\n",
      "Feature: Volume2                        \t Importance: 0.03294033780912232\n",
      "Feature: Volume10                       \t Importance: 0.011135512383629418\n",
      "Feature: Volume9                        \t Importance: 0.00983121122393737\n",
      "Feature: Volume5                        \t Importance: 0.007562024052085756\n",
      "random_forest 50 on train: : MSE = 4.055710e+16, R2 = 0.982, confidence interval 95% = (-10,623,864 - 1,518,504)\n",
      "random_forest 50 on test:: MSE = 2.554364e+17, R2 = -0.429, confidence interval 95% = (-87,492,594 - 1,020,716)\n",
      "\n",
      "First 5 Feature importances 100:\n",
      "Feature: Volume1                        \t Importance: 0.806675450887477\n",
      "Feature: Volume2                        \t Importance: 0.030235352101031673\n",
      "Feature: Volume9                        \t Importance: 0.010406115566956788\n",
      "Feature: Volume10                       \t Importance: 0.009045476766428875\n",
      "Feature: Volume3                        \t Importance: 0.007173552498003768\n",
      "random_forest 100 on train: : MSE = 4.177939e+16, R2 = 0.981, confidence interval 95% = (-6,817,589 - 5,579,932)\n",
      "random_forest 100 on test:: MSE = 2.508420e+17, R2 = -0.496, confidence interval 95% = (-68,405,155 - 19,308,534)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in (1,3,5,10,50,100):\n",
    "    eval_random_forest_model(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious from the comparison between train and test results that the model has high variance, it overfits to the train set. The decision tree regression model is not suitable for the task.  is Le't see SVM model, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_model(features, volume):\n",
    "    regressor = SVR()\n",
    "    \n",
    "    regressor.fit(features, volume)\n",
    "    return regressor\n",
    "\n",
    "\n",
    "def eval_svm_model(n):\n",
    "    # prepare the features\n",
    "    df_enriched = reader.prepare_window_features_for_training(df, n)[n:]\n",
    "\n",
    "    train_features, train_volume = reader.get_train_data(df_enriched)\n",
    "    test_features, test_volume = reader.get_test_data(df_enriched)\n",
    "\n",
    "    regressor = svm_model(train_features, train_volume)\n",
    "\n",
    "    print(evaluator.evaluate(\"random_forest {} on train: \".format(n), regressor.predict(train_features), train_volume))\n",
    "    random_forest_result = evaluator.evaluate(\"random_forest {} on test:\".format(n), regressor.predict(test_features), test_volume)\n",
    "    print(random_forest_result)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/work/github/trade_volume_prediction/venv/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest 1 on train: : MSE = 2.987715e+17, R2 = 0.857, confidence interval 95% = (22,203,979 - 54,970,986)\n",
      "random_forest 1 on test:: MSE = 2.841244e+17, R2 = 0.135, confidence interval 95% = (-27,130,374 - 66,221,161)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/work/github/trade_volume_prediction/venv/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest 2 on train: : MSE = 2.579920e+17, R2 = 0.877, confidence interval 95% = (18,432,532 - 48,884,906)\n",
      "random_forest 2 on test:: MSE = 2.460071e+17, R2 = 0.107, confidence interval 95% = (-15,977,399 - 70,886,847)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/work/github/trade_volume_prediction/venv/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest 3 on train: : MSE = 2.479718e+17, R2 = 0.882, confidence interval 95% = (14,772,783 - 44,631,416)\n",
      "random_forest 3 on test:: MSE = 2.466826e+17, R2 = 0.048, confidence interval 95% = (-14,763,232 - 72,220,184)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/work/github/trade_volume_prediction/venv/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest 5 on train: : MSE = 2.272681e+17, R2 = 0.892, confidence interval 95% = (15,414,757 - 44,006,437)\n",
      "random_forest 5 on test:: MSE = 2.611143e+17, R2 = 0.006, confidence interval 95% = (-32,201,483 - 57,290,172)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/work/github/trade_volume_prediction/venv/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest 10 on train: : MSE = 2.040400e+17, R2 = 0.903, confidence interval 95% = (12,209,797 - 39,316,855)\n",
      "random_forest 10 on test:: MSE = 2.597789e+17, R2 = -0.081, confidence interval 95% = (-47,058,810 - 42,203,708)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/work/github/trade_volume_prediction/venv/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest 50 on train: : MSE = 1.565243e+17, R2 = 0.924, confidence interval 95% = (12,105,240 - 35,959,218)\n",
      "random_forest 50 on test:: MSE = 2.750435e+17, R2 = -0.960, confidence interval 95% = (-38,804,714 - 53,042,907)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/work/github/trade_volume_prediction/venv/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest 100 on train: : MSE = 1.463036e+17, R2 = 0.926, confidence interval 95% = (14,169,781 - 37,369,423)\n",
      "random_forest 100 on test:: MSE = 2.787748e+17, R2 = -0.902, confidence interval 95% = (-66,944,709 - 25,523,821)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in (1, 2, 3,5,10,50,100):\n",
    "    eval_svm_model(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best SVM model is again the least overfitted, with only latest value of Volume and AdjCloseDiff1, and seasonality features (DayOfWeek, Month). The R2 = 0.135, with confidence interval 95% of average error = (-27,130,374 - 66,221,161)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seem that we are not moving forward a lot with traditional ML models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
