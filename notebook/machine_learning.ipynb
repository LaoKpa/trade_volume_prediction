{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "from util.read_data import DataReader\n",
    "from util.evaluator import ModelEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will usually use normalized features and volume. The volume will be denormalized only for the purpose of model evaluation. We will use StandardScaler for normalization.\n",
    "\n",
    "We can draw conclusion from the Exploratory Data Analysis that not all features from the original dataset are usefull for prediction and few more additional features can be added. Models in this notebook will work with usually with following columns:\n",
    "\n",
    "| Feature  | Type | Description |\n",
    "| ------------- | ------------- ||\n",
    "| Volume X  | float64  |Historial trading volume shifted by X|\n",
    "| AdjCloseDiff X  | float64  |Historical difference between AdjClose price of two consecutive days shifted by X|\n",
    "| HighLowDiff X  | float64  ||Historical difference between High and Low price shifted by X|\n",
    "| DayOfWeek X  | one-hot |One-hot encoding value for each day|\n",
    "| Month X  | one-hot  |One-hot encoding value for each month|\n",
    "\n",
    "Le'ts now read the normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = DataReader()\n",
    "df = reader.read_all_data_normalized()\n",
    "evaluator = ModelEvaluator(reader.label_scaler)\n",
    "\n",
    "df_test_features, series_test_volume = reader.get_test_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model is very simple, predicting the same value of Volume as yesterday: $\\hat{E}[v_{d+1}]=v_d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(volume):\n",
    "    pred_volume = volume.shift(1)\n",
    "    return pred_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: MSE = 3.684400e+17, R2 = 0.033, conf. int. 95% of error = (-53,069,427 - 53,341,067)\n"
     ]
    }
   ],
   "source": [
    "baseline_pred_volume = baseline_model(series_test_volume)\n",
    "# the first value is nan, we will ignore them by mapping [1:]\n",
    "baseline_model_results = evaluator.evaluate(\"baseline\", series_test_volume[1:], baseline_pred_volume[1:])\n",
    "print(baseline_model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline r2 score is **0.033**, which is slightly better than predicting average value.\n",
    "\n",
    "Another simple model would use moving average over some time window.\n",
    "The model is following: $V_{d+1}=\\frac 1n \\sum_{i=0}^{n-1} V_{d-i}$.\n",
    "We can try multiple n values, le'ts try following values: {1, 3, 5, 10, 50, 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_model(volume, n):\n",
    "    pred_volume = volume.rolling(n).mean().shift(1)\n",
    "    return pred_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving_average 1: MSE = 3.684400e+17, R2 = 0.033, conf. int. 95% of error = (-53,069,427 - 53,341,067)\n",
      "moving_average 2: MSE = 3.136891e+17, R2 = 0.178, conf. int. 95% of error = (-49,344,246 - 48,940,358)\n",
      "moving_average 3: MSE = 3.099159e+17, R2 = 0.189, conf. int. 95% of error = (-49,530,282 - 48,259,465)\n",
      "moving_average 4: MSE = 3.130410e+17, R2 = 0.182, conf. int. 95% of error = (-50,315,382 - 48,064,990)\n",
      "moving_average 5: MSE = 3.128615e+17, R2 = 0.184, conf. int. 95% of error = (-52,614,748 - 45,836,522)\n",
      "moving_average 8: MSE = 3.332384e+17, R2 = 0.136, conf. int. 95% of error = (-59,016,798 - 42,898,679)\n",
      "moving_average 10: MSE = 3.298599e+17, R2 = 0.147, conf. int. 95% of error = (-62,279,075 - 39,324,762)\n",
      "moving_average 15: MSE = 3.368760e+17, R2 = 0.136, conf. int. 95% of error = (-68,739,344 - 34,466,184)\n",
      "moving_average 20: MSE = 3.577937e+17, R2 = 0.089, conf. int. 95% of error = (-73,827,894 - 33,084,952)\n",
      "moving_average 50: MSE = 3.892483e+17, R2 = 0.057, conf. int. 95% of error = (-91,775,513 - 23,387,014)\n"
     ]
    }
   ],
   "source": [
    "window_size = [1,2,3,4,5,8,10,15,20,50]\n",
    "# first few initial values will have nan values, we will ignorem them by mapping [n:]\n",
    "moving_average_result_list = [evaluator.evaluate(\"moving_average {}\".format(n), \n",
    "    series_test_volume[n:],\n",
    "    moving_average_model(series_test_volume, n)[n:]) \n",
    "    for n in window_size]\n",
    "\n",
    "for result in moving_average_result_list:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moving average models improve the baseline , with the best R2 score = **0.189** for window size = 3. The window size 1 also confirms that the algorithm has correct implementation, as it has the same results as the baseline model.\n",
    "\n",
    "Le'ts try to use exponential moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_moving_average_model(volume, n):\n",
    "    pred_volume = volume.ewm(span=n).mean().shift(1)\n",
    "    return pred_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving_average 1: MSE = 3.684400e+17, R2 = 0.033, conf. int. 95% of error = (-53,069,427 - 53,341,067)\n",
      "moving_average 2: MSE = 3.024401e+17, R2 = 0.207, conf. int. 95% of error = (-48,491,694 - 48,014,561)\n",
      "moving_average 3: MSE = 2.880625e+17, R2 = 0.246, conf. int. 95% of error = (-48,026,359 - 46,252,592)\n",
      "moving_average 4: MSE = 2.844844e+17, R2 = 0.257, conf. int. 95% of error = (-49,530,117 - 44,255,685)\n",
      "moving_average 5: MSE = 2.845396e+17, R2 = 0.258, conf. int. 95% of error = (-51,352,553 - 42,536,855)\n",
      "moving_average 8: MSE = 2.907816e+17, R2 = 0.246, conf. int. 95% of error = (-54,959,423 - 40,242,576)\n",
      "moving_average 10: MSE = 2.953661e+17, R2 = 0.237, conf. int. 95% of error = (-58,118,071 - 38,026,698)\n",
      "moving_average 15: MSE = 3.063394e+17, R2 = 0.215, conf. int. 95% of error = (-64,181,541 - 34,235,284)\n",
      "moving_average 20: MSE = 3.151585e+17, R2 = 0.198, conf. int. 95% of error = (-67,282,532 - 33,058,379)\n",
      "moving_average 50: MSE = 3.594106e+17, R2 = 0.129, conf. int. 95% of error = (-84,893,406 - 25,767,251)\n"
     ]
    }
   ],
   "source": [
    "window_size = [1,2,3,4,5,8,10,15,20,50]\n",
    "exp_moving_average_result_list = [evaluator.evaluate(\"moving_average {}\".format(n), \n",
    "        series_test_volume[n:],\n",
    "        exp_moving_average_model(series_test_volume, n)[n:])\n",
    "                                                 for n in window_size]\n",
    "\n",
    "for result in exp_moving_average_result_list:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential moving average again improves the score, with the best R2 score = **0.258** for window size = 5.\n",
    "\n",
    "Let's now try to learn linear regression, on the normalized historical features described in the table on the top of the notebook. The time window size will be variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linear_regression_model(features, volume):\n",
    "    regressor = LinearRegression()\n",
    "    \n",
    "    regressor.fit(features, volume)\n",
    "    return regressor\n",
    "\n",
    "def eval_model(name, model_function, n, custom_callback=None, train_date_from = None):\n",
    "    # prepare the features, first rows with nan values will not be included\n",
    "    df_enriched = reader.prepare_window_features_for_training(df, n)[n:]\n",
    "    if (train_date_from != None):\n",
    "        df_enriched = df_enriched.loc[train_date_from:]\n",
    "\n",
    "    train_features, train_volume = reader.get_train_data(df_enriched)\n",
    "    test_features, test_volume = reader.get_test_data(df_enriched)\n",
    "\n",
    "    regressor = model_function(train_features, train_volume)\n",
    "    \n",
    "    # allows to custom-enrich the results output\n",
    "    if (custom_callback):\n",
    "        random_forest_callback(train_features, regressor)\n",
    "    \n",
    "    print(evaluator.evaluate(\"{} {} on train\".format(name, n), \n",
    "                             regressor.predict(train_features), train_volume))\n",
    "    result = evaluator.evaluate(\"{} {} on test \".format(name, n), \n",
    "                                regressor.predict(test_features), test_volume)\n",
    "    print(result)\n",
    "    print()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin. reg. 1 on train: MSE = 3.346656e+17, R2 = 0.842, conf. int. 95% of error = (-17,339,747 - 17,339,747)\n",
      "lin. reg. 1 on test : MSE = 3.178947e+17, R2 = -0.090, conf. int. 95% of error = (3,956,311 - 102,699,885)\n",
      "\n",
      "lin. reg. 3 on train: MSE = 2.906242e+17, R2 = 0.866, conf. int. 95% of error = (-16,162,359 - 16,162,359)\n",
      "lin. reg. 3 on test : MSE = 2.635186e+17, R2 = -0.092, conf. int. 95% of error = (-6,622,419 - 83,280,301)\n",
      "\n",
      "lin. reg. 5 on train: MSE = 2.809084e+17, R2 = 0.871, conf. int. 95% of error = (-15,853,735 - 15,933,504)\n",
      "lin. reg. 5 on test : MSE = 2.545230e+17, R2 = -0.114, conf. int. 95% of error = (-7,600,602 - 80,754,319)\n",
      "\n",
      "lin. reg. 10 on train: MSE = 2.721709e+17, R2 = 0.875, conf. int. 95% of error = (-15,669,396 - 15,637,903)\n",
      "lin. reg. 10 on test : MSE = 2.511179e+17, R2 = -0.187, conf. int. 95% of error = (-11,347,578 - 76,414,330)\n",
      "\n",
      "lin. reg. 50 on train: MSE = 2.548655e+17, R2 = 0.883, conf. int. 95% of error = (-15,216,464 - 15,222,191)\n",
      "lin. reg. 50 on test : MSE = 2.611820e+17, R2 = -0.232, conf. int. 95% of error = (-6,779,900 - 82,723,361)\n",
      "\n",
      "lin. reg. 100 on train: MSE = 2.392647e+17, R2 = 0.890, conf. int. 95% of error = (-14,832,120 - 14,836,216)\n",
      "lin. reg. 100 on test : MSE = 2.809531e+17, R2 = -0.172, conf. int. 95% of error = (1,399,815 - 94,228,918)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in (1,3,5,10,50,100):\n",
    "    eval_model(\"lin. reg.\", linear_regression_model, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linera regression does not seem to have very good results. The best R2 score on the test set is still not as good as predicting mean value.\n",
    "\n",
    "Let's not try to use another, random forest regressor, with the same features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def random_forest_model(features, volume):\n",
    "    regressor = RandomForestRegressor(n_estimators=100)\n",
    "    \n",
    "    regressor.fit(features, volume)\n",
    "    return regressor\n",
    "\n",
    "def random_forest_callback(train_features, regressor):\n",
    "    importances = list(zip(train_features.columns, regressor.feature_importances_))\n",
    "    importances.sort(key=lambda x: x[1], reverse = True)\n",
    "    print(\"First 5 Feature importances:\".format(n))\n",
    "    for importance in importances[:5]:\n",
    "        print('Feature: {:30} \\t Importance: {}'.format(importance[0], importance[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Feature importances:\n",
      "Feature: Volume1                        \t Importance: 0.8946135869153913\n",
      "Feature: HighLowDiff1                   \t Importance: 0.03070479293932718\n",
      "Feature: AdjCloseDiff1                  \t Importance: 0.028191001466756384\n",
      "Feature: DayOfWeek_Monday               \t Importance: 0.00903923260466571\n",
      "Feature: Month_12                       \t Importance: 0.0043292836188353855\n",
      "random_forest 1 on train: MSE = 4.762153e+16, R2 = 0.979, conf. int. 95% of error = (-7,766,657 - 5,315,185)\n",
      "random_forest 1 on test : MSE = 3.048690e+17, R2 = 0.002, conf. int. 95% of error = (-108,384,749 - -11,685,343)\n",
      "\n",
      "First 5 Feature importances:\n",
      "Feature: Volume1                        \t Importance: 0.8294453893401988\n",
      "Feature: Volume2                        \t Importance: 0.06120432738544723\n",
      "Feature: Volume3                        \t Importance: 0.027123367870980578\n",
      "Feature: AdjCloseDiff1                  \t Importance: 0.012691976813380738\n",
      "Feature: HighLowDiff1                   \t Importance: 0.010553420696262772\n",
      "random_forest 3 on train: MSE = 4.046053e+16, R2 = 0.982, conf. int. 95% of error = (-8,179,726 - 3,881,309)\n",
      "random_forest 3 on test : MSE = 2.829604e+17, R2 = -0.008, conf. int. 95% of error = (-119,249,691 - -26,089,573)\n",
      "\n",
      "First 5 Feature importances:\n",
      "Feature: Volume1                        \t Importance: 0.823879074517222\n",
      "Feature: Volume2                        \t Importance: 0.044405683129383214\n",
      "Feature: Volume5                        \t Importance: 0.022234851461709247\n",
      "Feature: Volume4                        \t Importance: 0.01838262856632563\n",
      "Feature: Volume3                        \t Importance: 0.016118285983525712\n",
      "random_forest 5 on train: MSE = 4.050252e+16, R2 = 0.982, conf. int. 95% of error = (-8,998,084 - 3,072,032)\n",
      "random_forest 5 on test : MSE = 2.811621e+17, R2 = -0.084, conf. int. 95% of error = (-118,231,981 - -25,368,373)\n",
      "\n",
      "First 5 Feature importances:\n",
      "Feature: Volume1                        \t Importance: 0.815912244195939\n",
      "Feature: Volume2                        \t Importance: 0.03630309128141335\n",
      "Feature: Volume9                        \t Importance: 0.015306564100268172\n",
      "Feature: Volume10                       \t Importance: 0.012584682232710975\n",
      "Feature: Volume4                        \t Importance: 0.011957805963882963\n",
      "random_forest 10 on train: MSE = 3.950481e+16, R2 = 0.983, conf. int. 95% of error = (-8,959,013 - 2,968,495)\n",
      "random_forest 10 on test : MSE = 2.705095e+17, R2 = -0.198, conf. int. 95% of error = (-110,298,768 - -19,211,339)\n",
      "\n",
      "First 5 Feature importances:\n",
      "Feature: Volume1                        \t Importance: 0.815304907607197\n",
      "Feature: Volume2                        \t Importance: 0.03008316942553186\n",
      "Feature: Volume10                       \t Importance: 0.015297226027116594\n",
      "Feature: Volume9                        \t Importance: 0.010317779883653535\n",
      "Feature: Volume5                        \t Importance: 0.010158512220757896\n",
      "random_forest 20 on train: MSE = 4.116901e+16, R2 = 0.982, conf. int. 95% of error = (-8,554,111 - 3,636,331)\n",
      "random_forest 20 on test : MSE = 2.786330e+17, R2 = -0.336, conf. int. 95% of error = (-108,889,472 - -16,444,455)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in (1,3,5,10,20):\n",
    "    eval_model(\"random_forest\", random_forest_model, n, random_forest_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious from the comparison between train and test results that the model has high variance, it overfits to the train set. The best R2 score is around **0.010** (changes with each run), for window size = 5  The decision tree regression model is not suitable for the task.\n",
    "\n",
    "**Insights:**\n",
    "* Model easily overfits to the train set\n",
    "* The sorted list of feature importances shows that the most important feature for decission is Volume(t-1), which is expected result.  \n",
    "* The AdjCloseDiff1(t-1) and HighLowDiff1(t-1) does not seem important at all\n",
    "\n",
    "\n",
    "is Le't see SVM model, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "def svm_model(features, volume):\n",
    "    regressor = SVR(gamma='auto')\n",
    "    \n",
    "    regressor.fit(features, volume)\n",
    "    return regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_model 1 on train: MSE = 2.952591e+17, R2 = 0.859, conf. int. 95% of error = (23,015,390 - 55,589,224)\n",
      "svm_model 1 on test : MSE = 3.036388e+17, R2 = 0.069, conf. int. 95% of error = (-7,893,085 - 88,611,036)\n",
      "\n",
      "svm_model 2 on train: MSE = 2.541464e+17, R2 = 0.879, conf. int. 95% of error = (17,333,138 - 47,557,698)\n",
      "svm_model 2 on test : MSE = 2.722919e+17, R2 = -0.000, conf. int. 95% of error = (1,910,299 - 93,297,325)\n",
      "\n",
      "svm_model 3 on train: MSE = 2.413306e+17, R2 = 0.886, conf. int. 95% of error = (15,724,379 - 45,180,461)\n",
      "svm_model 3 on test : MSE = 2.640269e+17, R2 = 0.018, conf. int. 95% of error = (-7,293,575 - 82,695,807)\n",
      "\n",
      "svm_model 5 on train: MSE = 2.226577e+17, R2 = 0.894, conf. int. 95% of error = (11,552,309 - 39,852,495)\n",
      "svm_model 5 on test : MSE = 2.735825e+17, R2 = -0.020, conf. int. 95% of error = (-33,548,592 - 58,054,761)\n",
      "\n",
      "svm_model 10 on train: MSE = 2.003799e+17, R2 = 0.904, conf. int. 95% of error = (12,700,390 - 39,563,225)\n",
      "svm_model 10 on test : MSE = 2.803728e+17, R2 = -0.123, conf. int. 95% of error = (-59,083,253 - 33,649,922)\n",
      "\n",
      "svm_model 20 on train: MSE = 1.753106e+17, R2 = 0.916, conf. int. 95% of error = (7,942,905 - 33,098,718)\n",
      "svm_model 20 on test : MSE = 2.985330e+17, R2 = -0.410, conf. int. 95% of error = (-93,287,297 - 2,402,005)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in (1, 2, 3,5,10,20):\n",
    "    eval_model(\"svm_model\", svm_model, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best SVM model is again overfitted to the train set. The best R2 score is around 0.069 (changing with each run). \n",
    "\n",
    "It seem that we are not moving forward a lot with traditional ML models. Let's try one last model,  ridge regression with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def linear_ridge_model(features, volume):\n",
    "    regressor = linear_model.RidgeCV(alphas=[0.1, 0.5, 1.0, 5, 10.0], cv=5)\n",
    "    \n",
    "    regressor.fit(features, volume)\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/work/github/trade_volume_prediction/venv/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_ridge_model 1 on train: MSE = 3.346656e+17, R2 = 0.842, conf. int. 95% of error = (-17,339,747 - 17,339,747)\n",
      "linear_ridge_model 1 on test : MSE = 3.178889e+17, R2 = -0.090, conf. int. 95% of error = (3,962,585 - 102,705,255)\n",
      "\n",
      "linear_ridge_model 2 on train: MSE = 2.970075e+17, R2 = 0.862, conf. int. 95% of error = (-16,336,977 - 16,336,977)\n",
      "linear_ridge_model 2 on test : MSE = 2.728444e+17, R2 = -0.079, conf. int. 95% of error = (-4,418,830 - 87,060,873)\n",
      "\n",
      "linear_ridge_model 3 on train: MSE = 2.906243e+17, R2 = 0.866, conf. int. 95% of error = (-16,162,359 - 16,162,359)\n",
      "linear_ridge_model 3 on test : MSE = 2.635157e+17, R2 = -0.092, conf. int. 95% of error = (-6,620,907 - 83,281,329)\n",
      "\n",
      "linear_ridge_model 5 on train: MSE = 2.809087e+17, R2 = 0.871, conf. int. 95% of error = (-15,893,628 - 15,893,628)\n",
      "linear_ridge_model 5 on test : MSE = 2.545127e+17, R2 = -0.114, conf. int. 95% of error = (-7,640,096 - 80,713,027)\n",
      "\n",
      "linear_ridge_model 10 on train: MSE = 2.721949e+17, R2 = 0.875, conf. int. 95% of error = (-15,654,338 - 15,654,338)\n",
      "linear_ridge_model 10 on test : MSE = 2.509386e+17, R2 = -0.188, conf. int. 95% of error = (-11,363,247 - 76,367,315)\n",
      "\n",
      "linear_ridge_model 20 on train: MSE = 2.633851e+17, R2 = 0.879, conf. int. 95% of error = (-15,416,999 - 15,416,999)\n",
      "linear_ridge_model 20 on test : MSE = 2.618138e+17, R2 = -0.258, conf. int. 95% of error = (-13,145,880 - 76,465,568)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in (1, 2, 3,5,10,20):\n",
    "    eval_model(\"linear_ridge_model\", linear_ridge_model, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best R2 score with RidgeCV model on the test set is worse than predicting average Volume.\n",
    "\n",
    "The best model so far was simple model with exponential moving averate prediction.\n",
    "The next possible step with current data we have could be using exponential average with various spans as the features for linear models.\n",
    "\n",
    "**Hypothesis** More rewarding would probably be using more informative features. One of the possible such features could be number of expected earning announcements, ideally weighted by the market value of the company.\n",
    "\n",
    "**Hypothesis** No model with the features used does not have very good performance. The hypothesis is that **historical Market data on its own are not very good features to predict next trade Volume. The market reaches equilibrium at the end of each date and all available information was already processed.**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
